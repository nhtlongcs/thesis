\section{Motivations}
\label{sec:motivation}
The Natural Language-Based Vehicle Retrieval track is really tough since it requires applying knowledge across CV and NL Processing. Despite this, it promises an important and practical problem. There are three reasons supporting this statement.

Firstly, search is a must-have function in any large system. It is not the issue that data is so colossal and people can never manually remember all of its features, but it is the duty of intelligent systems when they must have the ability to filter robustly, sort quickly, and give the best possible results to satisfy the users' expectations. There are two aspects users are concerned with when making a search: (i) the form of input, (ii) the data processed and returned for them. With regard to input, the most basic and convenient way to retrieve is by giving the system a textual query. Meanwhile, in transportation, they want to get information about traffic events, which were recorded as videos, the most. Also, as mentioned in section [x] , people pay greater attention to the vehicle than any object as it is the focal point of all activities. Therefore, building the model capable of identifying the best-matching video with descriptions about a vehicle’s information like motion attributes, appearance features, relations to other in-traffic vehicles, and other relevant events is fundamental but crucial for the ITS.

Secondly, there has not been any accurate baselined method for this track. Although the Video Retrieval problem has recently been on an upward trend, it lacks development in particular objects. In very general domains, people still have been confronted by a semantic gap between two modalities. This track concentrates on a specific domain - vehicle, so making the gap become more challenging than ever, when the model needs to not only grasp the textual input but also to be able to discriminate among so many similar vehicles and their events to process the video contents. It is extremely necessary to propose constructive-developmental approaches for this problem.

Finally, it is about the impact. We hope that the model in particular, and the NL-based VR track in general, can get greater attention to advanced progress: (i) make the model deeply understand more insights from the NL inputs so as to narrow the semantic gap to videos, (ii) make use of other data types such as GPS, velocity, traffic volume, etc. from various sensor sources to perform better outcomes, as a premiere for future deployments in law enforcement, or other search-oriented modules in traffic administration. Furthermore, the objective of researching cutting-edge models is not only to put it into practice but also to expand the retrieval’s influence in divergent non-human areas. It is an expectation that these models would serve as a starting point for retrieval problems targeting objects like the plant, animal, leaf, insect, etc. in Agriculture, the organ, cell in Medical, or the food, beverage in F\&B service, and so on.

As a result, the NL-based VR problem has a genuine chance of being widely researched and integrated into ITSs.
It can be treated as cross-modal retrieval of visual data using natural language descriptions. The typical approach for such problems is to embed visual and textual information into the same semantic space for similarity measurement. 
Handling the problem this way requires a large training dataset enough for the model to learn various types of descriptions.
In the scope of practical vehicle-oriented retrieval, the queries mainly concentrate on describing the target vehicles while the video provides both targets’ attributes and trajectories. 
Another restriction of practical problems for deep modeling is that the available learning dataset is usually small due to labor-intensive and uncertain real-life conditions. 

Therefore, to efficiently handle the ITS city-scale retrieval problem, current state-of-the-art approaches explore different ways to embed both the global context of the entire video and local context containing target vehicle features for a better representation. Furthermore, to tackle the shortage of valuable datasets, they ensemble features from multiple backbones and extract richer features to achieve potential results. 
These methods provide end-to-end processes but lack explainability and cost extensive computational power due to the usage of many deep learning models, which may lead to difficulty for real-life deployment.
Other approaches focus on descriptive querying cues to perform searching. They propose hierarchical systems to filter different attributes of the target vehicle such as color, vehicle type, moving directions, etc. Tackling the problem this way is more explainable and reduces the hardware computational stress, but it highly depends on the quality of training data. 

These disadvantages motivate us to build a system with less computing cost, more explainability, and high possibility of real-life deployment.
We propose a multi-module vehicle-based retrieval system that does not depend too much on deep models but also concentrates on different attributes of the mentioned vehicle and produces competitive results.
We inherit the success of representation learning-based approaches to implement a retrieval module that returns a list of candidate videos for each query. Then, we adopt different modules; each is responsible for capturing an essential attribute of the target vehicle to refine the candidate result. Experiments show that our proposed approach achieves state-of-the-art results with only a single embedding model.

